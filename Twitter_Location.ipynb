{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date, timedelta, datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'xxxxxxxxl0VJAJSp9Ob4xxxxxx'\n",
    "consumer_secret= 'xxxxxBx1InIFRtdOEIJGxvx2Mxxx'\n",
    "access_token= 'xxxxmLD5g4aEDppJUD3ghn9xxxxxx'\n",
    "access_token_secret= 'xxxxxxXflBur7pq4SbqwxYZR9vwDcxxxxx'\n",
    "\n",
    "#auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth = tw.AppAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = date.today() - timedelta(days=1)\n",
    "today = date.today()\n",
    "\n",
    "search_words = \"TheJoker OR TheJokerFILM OR JokerFilm OR TheJOKERmovie OR jokermovie\" + \" -filter:retweets\"\n",
    "date_since = \"2019-10-08\"\n",
    "date_until = \"2019-10-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       since=date_since,\n",
    "                       until=today,\n",
    "                       result_type=\"recent\",\n",
    "                        tweet_mode=\"extended\").items(2000)\n",
    "\n",
    "users_locs = [[tweet.user.name, tweet.lang, tweet.user.location, tweet.coordinates, tweet.created_at,tweet.favorite_count,tweet.retweet_count,tweet.user.followers_count,tweet.user.verified, tweet.full_text] for tweet in tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.DataFrame(data=users_locs,columns=['username','language','location', 'coordinates','created_at',\n",
    "                                                     'favorite_count','retweet_count','followers','verified','text'])\n",
    "\n",
    "twitter_data['created_at'] = twitter_data['created_at'] + timedelta(hours=2)\n",
    "\n",
    "twitter_data = twitter_data[['username','language','location','coordinates','created_at','favorite_count',\n",
    "                             'retweet_count','followers','verified','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_name_and_link(w):\n",
    "  return   ' '.join(re.sub(\"(@[A-Za-z0-9]+) | (\\nhttps?://[A-Za-z0-9./]*) |(https?://[A-Za-z0-9./]*)| (//t.[A-Za-z0-9./]*) | (RT @[\\w]*:) |(@[\\w]*)\",\" \",w).split())\n",
    "\n",
    "twitter_data['text_clean'] = twitter_data['text'].apply(remove_name_and_link)\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "     score = analyser.polarity_scores(sentence)\n",
    "     print(score)\n",
    "\n",
    "tweet = []\n",
    "compound = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "\n",
    "for i in range(0, len(twitter_data)):\n",
    "    tweet.append(twitter_data['text_clean'][i])\n",
    "    compound.append(analyser.polarity_scores(twitter_data['text_clean'][i])['compound'])\n",
    "    positive.append(analyser.polarity_scores(twitter_data['text_clean'][i])['pos'])\n",
    "    neutral.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neu'])\n",
    "    negative.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neg'])\n",
    " \n",
    "\n",
    "twitter_data['compound']=compound\n",
    "twitter_data['positive']=positive\n",
    "twitter_data['neutral']=neutral\n",
    "twitter_data['negative']=negative\n",
    "\n",
    "twitter_data = twitter_data[['created_at','username','verified','location','coordinates','language','favorite_count','retweet_count','followers','compound','positive','neutral','negative','text','text_clean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(w):\n",
    "     if w >= 0.05:\n",
    "            return \"positive\"\n",
    "     elif (w < 0.05) and (w > -0.05):\n",
    "            return \"neutral\"\n",
    "     else:\n",
    "            return \"negative\"\n",
    "\n",
    "        \n",
    "twitter_data['general_sen'] = twitter_data['compound'].apply(sentiment_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_csv = twitter_data.to_csv (r'C:\\\\Users\\\\User\\twitlocati.csv', index = True, header=True,sep=\";\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data=  pd.read_excel('canadaloc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = twitter_data.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Coordinates from Location String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"st3553ggd\")\n",
    "\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_location(item):\n",
    "\n",
    "    try:\n",
    "        language = geolocator.geocode(item)\n",
    "        return(language.latitude,language.longitude)\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coordinates'] = df['language'].apply(geo_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['coordinates'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "#df2 = df.copy()\n",
    "#df3 = df.copy()\n",
    "#df4 = df.copy()\n",
    "#df5 = df.copy()\n",
    "#df6 = df.copy()\n",
    "#df7 = df.copy()\n",
    "#df8 = df.copy()\n",
    "#df9 = df.copy()\n",
    "#df10 = df.copy()\n",
    "#df11 = df.copy()\n",
    "#df12 = df.copy()\n",
    "#df13 = df.copy()\n",
    "#df14 = df.copy()\n",
    "#df15 = df.copy()\n",
    "#df16 = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(mydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result.location !=\"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result['location'] = result['location'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result['location']:\n",
    "    if (item == 'NaN'):\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dropna(subset=['location'], how = 'any',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "\n",
    "for i, item in enumerate(result.location):\n",
    "    if (item == 'nan'):\n",
    "        l.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index = list(range(0,16000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result.drop(labels = l, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['coordinates'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save file in csv format\n",
    "\n",
    "export_csv = r.to_csv (r'C:\\\\Users\\\\User\\twitterlocation.csv', index = True, header=True,sep=\";\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
