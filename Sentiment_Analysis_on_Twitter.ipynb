{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date, timedelta, datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'xxxpejEeRjl0VJAJSp9Ob4xxx'\n",
    "consumer_secret= 'xxxsV4yayNBx1InIFRtdOEIJGxvx2MRawuuoARa5xEe4PIpxxx'\n",
    "access_token= 'xxx3536113492942849-mM10EmLD5g4aEDppJUD3ghn96nCxxx'\n",
    "access_token_secret= 'xxxOvLRAiADzQe9CsJXflBur7pq4SbqwxYZR9vwDchxxx'\n",
    "\n",
    "#auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth = tw.AppAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Tweets about \"Trudeau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = date.today() - timedelta(days=1)\n",
    "today = date.today()\n",
    "\n",
    "search_words = \"trudeau\" + \" -filter:retweets\"\n",
    "\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang='en',\n",
    "                       since=yesterday,\n",
    "                       until=today,\n",
    "                       result_type=\"recent\",\n",
    "                        tweet_mode=\"extended\").items(200000)\n",
    "\n",
    "users_locs = [[tweet.user.name, tweet.lang, tweet.user.location, tweet.created_at,tweet.favorite_count,\n",
    "               tweet.retweet_count,tweet.user.followers_count,\n",
    "               tweet.user.verified, tweet.full_text] for tweet in tweets]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 280)\n",
    "\n",
    "#build data frame\n",
    "twitter_data = pd.DataFrame(data=users_locs,columns=['username','language','location','created_at',\n",
    "                                                     'favorite_count','retweet_count','followers','verified',\n",
    "                                                     'text'])\n",
    "\n",
    "#sort columns\n",
    "twitter_data = twitter_data[['username','language','location','created_at','favorite_count','retweet_count',\n",
    "                             'followers','verified','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_name_and_link(w):\n",
    "  return   ' '.join(re.sub(\"(@[A-Za-z0-9]+) | (\\nhttps?://[A-Za-z0-9./]*) |(https?://[A-Za-z0-9./]*)|(//t.[A-Za-z0-9./]*) | (RT @[\\w]*:) |(@[\\w]*)\",\" \",w).split())\n",
    "\n",
    "twitter_data['text_clean'] = twitter_data['text'].apply(remove_name_and_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "     score = analyser.polarity_scores(sentence)\n",
    "     print(score)\n",
    "\n",
    "tweet = []\n",
    "compound = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "\n",
    "for i in range(0, len(twitter_data)):\n",
    "    tweet.append(twitter_data['text_clean'][i])\n",
    "    compound.append(analyser.polarity_scores(twitter_data['text_clean'][i])['compound'])\n",
    "    positive.append(analyser.polarity_scores(twitter_data['text_clean'][i])['pos'])\n",
    "    neutral.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neu'])\n",
    "    negative.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neg'])\n",
    " \n",
    "\n",
    "twitter_data['compound']=compound\n",
    "twitter_data['positive']=positive\n",
    "twitter_data['neutral']=neutral\n",
    "twitter_data['negative']=negative\n",
    "\n",
    "twitter_data = twitter_data[['created_at','username','verified','location','language','favorite_count',\n",
    "                             'retweet_count','followers','compound','positive','neutral','negative',\n",
    "                             'text','text_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize Sentiment into 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(w):\n",
    "     if w >= 0.05:\n",
    "            return \"positive\"\n",
    "     elif (w < 0.05) and (w > -0.05):\n",
    "            return \"neutral\"\n",
    "     else:\n",
    "            return \"negative\"\n",
    "\n",
    "        \n",
    "twitter_data['general_sen'] = twitter_data['compound'].apply(sentiment_analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Data on SQL Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@35.239.145.12:3306/{db}\".format(user=\"username\",pw=\"password\",db=\"twitterdb\"))\n",
    "\n",
    "twitter_data.to_sql('canada', con = engine, if_exists = 'append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Tweets about \"Scheer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"scheer\" + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang='en',\n",
    "                       since=yesterday,\n",
    "                       until=today,\n",
    "                       result_type=\"recent\",\n",
    "                        tweet_mode=\"extended\").items(200000)\n",
    "\n",
    "users_locs = [[tweet.user.name, tweet.lang, tweet.user.location, tweet.created_at,tweet.favorite_count,\n",
    "               tweet.retweet_count,tweet.user.followers_count,tweet.user.verified,\n",
    "               tweet.full_text] for tweet in tweets]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 280)\n",
    "\n",
    "\n",
    "twitter_data = pd.DataFrame(data=users_locs,columns=['username','language','location','created_at',\n",
    "                                                     'favorite_count','retweet_count','followers','verified',\n",
    "                                                     'text'])\n",
    "\n",
    "\n",
    "twitter_data = twitter_data[['username','language','location','created_at','favorite_count','retweet_count',\n",
    "                             'followers','verified','text']]\n",
    "\n",
    "#Data Cleaning\n",
    "\n",
    "def remove_name_and_link(w):\n",
    "  return   ' '.join(re.sub(\"(@[A-Za-z0-9]+) | (\\nhttps?://[A-Za-z0-9./]*) |(https?://[A-Za-z0-9./]*)| (//t.[A-Za-z0-9./]*) | (RT @[\\w]*:) |(@[\\w]*)\",\" \",w).split())\n",
    "\n",
    "twitter_data['text_clean'] = twitter_data['text'].apply(remove_name_and_link)\n",
    "\n",
    "#Sentiment Analysis\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "     score = analyser.polarity_scores(sentence)\n",
    "     print(score)\n",
    "\n",
    "tweet = []\n",
    "compound = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "\n",
    "for i in range(0, len(twitter_data)):\n",
    "    tweet.append(twitter_data['text_clean'][i])\n",
    "    compound.append(analyser.polarity_scores(twitter_data['text_clean'][i])['compound'])\n",
    "    positive.append(analyser.polarity_scores(twitter_data['text_clean'][i])['pos'])\n",
    "    neutral.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neu'])\n",
    "    negative.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neg'])\n",
    " \n",
    "\n",
    "twitter_data['compound']=compound\n",
    "twitter_data['positive']=positive\n",
    "twitter_data['neutral']=neutral\n",
    "twitter_data['negative']=negative\n",
    "\n",
    "twitter_data = twitter_data[['created_at','username','verified','location','language','favorite_count',\n",
    "                             'retweet_count','followers','compound','positive','neutral','negative','text',\n",
    "                             'text_clean']]\n",
    "\n",
    "#categorize sentiment into 3 classes\n",
    "\n",
    "def sentiment_analyzer(w):\n",
    "     if w >= 0.05:\n",
    "            return \"positive\"\n",
    "     elif (w < 0.05) and (w > -0.05):\n",
    "            return \"neutral\"\n",
    "     else:\n",
    "            return \"negative\"\n",
    "\n",
    "        \n",
    "twitter_data['general_sen'] = twitter_data['compound'].apply(sentiment_analyzer)\n",
    "\n",
    "#store data on SQL Google Cloud\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@35.239.145.12:3306/{db}\".format(user=\"username\",\n",
    "                                                                                    pw=\"password\",db=\"twitterdb\"))\n",
    "\n",
    "twitter_data.to_sql('canada', con = engine, if_exists = 'append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Tweets on \"The Joker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_words = \"TheJoker OR TheJokerFILM OR JokerFilm OR TheJOKERmovie OR jokermovie\" + \" -filter:retweets\"\n",
    "\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang='en',\n",
    "                       since=yesterday,\n",
    "                       until=today,\n",
    "                       result_type=\"recent\",\n",
    "                        tweet_mode=\"extended\").items(200000)\n",
    "\n",
    "users_locs = [[tweet.user.name, tweet.lang, tweet.user.location, tweet.created_at,tweet.favorite_count,\n",
    "               tweet.retweet_count,tweet.user.followers_count,tweet.user.verified,\n",
    "               tweet.full_text] for tweet in tweets]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 280)\n",
    "\n",
    "\n",
    "twitter_data = pd.DataFrame(data=users_locs,columns=['username','language','location','created_at',\n",
    "                                                     'favorite_count','retweet_count','followers','verified',\n",
    "                                                     'text'])\n",
    "\n",
    "\n",
    "twitter_data = twitter_data[['username','language','location','created_at','favorite_count','retweet_count',\n",
    "                             'followers','verified','text']]\n",
    "\n",
    "\n",
    "#Clean Data\n",
    "\n",
    "def remove_name_and_link(w):\n",
    "  return   ' '.join(re.sub(\"(@[A-Za-z0-9]+) | (\\nhttps?://[A-Za-z0-9./]*) |(https?://[A-Za-z0-9./]*)| (//t.[A-Za-z0-9./]*) | (RT @[\\w]*:) |(@[\\w]*)\",\" \",w).split())\n",
    "\n",
    "twitter_data['text_clean'] = twitter_data['text'].apply(remove_name_and_link)\n",
    "\n",
    "#Sentiment Analysis\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "     score = analyser.polarity_scores(sentence)\n",
    "     print(score)\n",
    "\n",
    "tweet = []\n",
    "compound = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "\n",
    "for i in range(0, len(twitter_data)):\n",
    "    tweet.append(twitter_data['text_clean'][i])\n",
    "    compound.append(analyser.polarity_scores(twitter_data['text_clean'][i])['compound'])\n",
    "    positive.append(analyser.polarity_scores(twitter_data['text_clean'][i])['pos'])\n",
    "    neutral.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neu'])\n",
    "    negative.append(analyser.polarity_scores(twitter_data['text_clean'][i])['neg'])\n",
    " \n",
    "\n",
    "twitter_data['compound']=compound\n",
    "twitter_data['positive']=positive\n",
    "twitter_data['neutral']=neutral\n",
    "twitter_data['negative']=negative\n",
    "\n",
    "twitter_data = twitter_data[['created_at','username','verified','location','language','favorite_count',\n",
    "                             'retweet_count','followers','compound','positive','neutral','negative','text',\n",
    "                             'text_clean']]\n",
    "\n",
    "#categorize sentiment into 3 classes\n",
    "\n",
    "def sentiment_analyzer(w):\n",
    "     if w >= 0.05:\n",
    "            return \"positive\"\n",
    "     elif (w < 0.05) and (w > -0.05):\n",
    "            return \"neutral\"\n",
    "     else:\n",
    "            return \"negative\"\n",
    "\n",
    "        \n",
    "twitter_data['general_sen'] = twitter_data['compound'].apply(sentiment_analyzer)\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@35.239.145.12:3306/{db}\".format(user=\"username\",\n",
    "                                                                                    pw=\"password\",db=\"twitterdb\"))\n",
    "\n",
    "twitter_data.to_sql('thejoker', con = engine, if_exists = 'append', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
